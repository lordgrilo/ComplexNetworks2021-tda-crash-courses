{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistent homology of correlation networks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import ripser, plot_dgms\n",
    "import numpy as np \n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use some fun data!   \n",
    "In the directory below you find timeseries for a 100 subjects for two recordings. \n",
    "They have been studied in [this](http://www.gipsa-lab.grenoble-inp.fr/~sophie.achard/Brain_connectivity_network) paper about test-retest reliability of brain functional networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here you can find timeseries for a 100 subjects for test and retest \n",
    "data_dir = '../data/corr-mats/TimeSeriesAAL/'\n",
    "\n",
    "fs = os.listdir(data_dir)\n",
    "ts_data = {}\n",
    "subs = []\n",
    "for f in fs:\n",
    "    sub = f.split('_')[1]\n",
    "    subs.append(sub)\n",
    "    test = int(f.split('_')[3][-1]);\n",
    "    if sub not in ts_data:\n",
    "        ts_data[sub] = {}\n",
    "    ts_data[sub][test] = np.loadtxt(data_dir+f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate correlation matrices the easy way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_dict = {}\n",
    "\n",
    "for sub in ts_data:\n",
    "    corr_dict[sub] = {}\n",
    "    for test in ts_data[sub]:\n",
    "        corr_dict[sub][test] = np.corrcoef(ts_data[sub][test].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ripser import Rips\n",
    "from persim import PersImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rips = Rips(maxdim=1, coeff=2, do_cocycles=False,thresh=2);\n",
    "diagrams_h1 = []\n",
    "labels = []\n",
    "for test in [0,1]:\n",
    "    for i,sub in enumerate(corr_dict):\n",
    "        labels.append(test);\n",
    "        # note that we use 1-corr because these are pearson correlations and hence \n",
    "        # this is a proper metric\n",
    "        dist = 1.0 - corr_dict[sub][test]\n",
    "        diagrams_h1.append(rips.fit_transform(dist,distance_matrix=True)[1]) #don't forget the distance matrix flag!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plot_dgms(diagrams_h1[i])\n",
    "    plt.ylim(0,1)\n",
    "    plt.xlim(0,1)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance matrices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgms = {}\n",
    "for i,sub in enumerate(corr_dict):\n",
    "    dgms[sub] = []\n",
    "    for test in [0,1]:\n",
    "        dgms[sub].append(rips.fit_transform(1.0 - corr_dict[sub][test],distance_matrix=True)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein distances inter- and intra-subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations;\n",
    "inter_dist = {}\n",
    "intra_dist = {}\n",
    "\n",
    "for s, ss in combinations(corr_dict.keys(),2):\n",
    "    if s not in intra_dist:\n",
    "        intra_dist[s] = persim.sliced_wasserstein(dgms[s][0],dgms[s][1],300);\n",
    "        inter_dist[s] = []\n",
    "    if ss not in intra_dist:\n",
    "        intra_dist[ss] = persim.sliced_wasserstein(dgms[ss][0],dgms[ss][1],300);\n",
    "        inter_dist[ss] = [];\n",
    "    d = persim.sliced_wasserstein(dgms[s][0],dgms[ss][1],300);\n",
    "    inter_dist[s].append(d);\n",
    "    d = persim.sliced_wasserstein(dgms[s][1],dgms[ss][0],300);\n",
    "    inter_dist[ss].append(d);\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  list(map(lambda x: intra_dist[x], corr_dict.keys()))\n",
    "y = list(map(lambda x: np.mean(inter_dist[x]), corr_dict.keys()))\n",
    "yerr = list(map(lambda x: np.std(inter_dist[x]), corr_dict.keys()))\n",
    "\n",
    "plt.plot(x,y,'o')\n",
    "plt.errorbar(x,y,yerr,fmt='.')\n",
    "plt.plot(np.linspace(0,1,10), np.linspace(0,1,10),'k--')\n",
    "print(np.sum([np.array(x)<np.array(y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bottleneck distances inter- and intra-subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_dist_b = {}\n",
    "intra_dist_b = {}\n",
    "\n",
    "for s, ss in combinations(corr_dict.keys(),2):\n",
    "    if s not in intra_dist_b:\n",
    "        intra_dist_b[s] = persim.bottleneck(dgms[s][0],dgms[s][1]);\n",
    "        inter_dist_b[s] = []\n",
    "    if ss not in intra_dist_b:\n",
    "        intra_dist_b[ss] = persim.bottleneck(dgms[ss][0],dgms[ss][1]);\n",
    "        inter_dist_b[ss] = [];\n",
    "    d = persim.bottleneck(dgms[s][0],dgms[ss][1]);\n",
    "    inter_dist_b[s].append(d);\n",
    "    d = persim.bottleneck(dgms[s][1],dgms[ss][0]);\n",
    "    inter_dist_b[ss].append(d);\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  list(map(lambda x: intra_dist_b[x], corr_dict.keys()))\n",
    "y = list(map(lambda x: np.mean(inter_dist_b[x]), corr_dict.keys()))\n",
    "yerr = list(map(lambda x: np.std(inter_dist_b[x]), corr_dict.keys()))\n",
    "\n",
    "plt.plot(x,y,'o')\n",
    "plt.errorbar(x,y,yerr,fmt='.')\n",
    "plt.plot(np.linspace(0,0.09,10), np.linspace(0,0.09,10),'k--')\n",
    "print(np.sum([np.array(x)<np.array(y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat kernel sims inter- and intra-subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_dist_h = {}\n",
    "intra_dist_h = {}\n",
    "\n",
    "for s, ss in combinations(corr_dict.keys(),2):\n",
    "    if s not in intra_dist_h:\n",
    "        intra_dist_h[s] = persim.heat(dgms[s][0],dgms[s][1]);\n",
    "        inter_dist_h[s] = []\n",
    "    if ss not in intra_dist_h:\n",
    "        intra_dist_h[ss] = persim.heat(dgms[ss][0],dgms[ss][1]);\n",
    "        inter_dist_h[ss] = [];\n",
    "    d = persim.heat(dgms[s][0],dgms[ss][1]);\n",
    "    inter_dist_h[s].append(d);\n",
    "    d = persim.heat(dgms[s][1],dgms[ss][0]);\n",
    "    inter_dist_h[ss].append(d);\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  list(map(lambda x: intra_dist_h[x], corr_dict.keys()))\n",
    "y = list(map(lambda x: np.mean(inter_dist_h[x]), corr_dict.keys()))\n",
    "yerr = list(map(lambda x: np.std(inter_dist_h[x]), corr_dict.keys()))\n",
    "\n",
    "plt.plot(x,y,'o')\n",
    "plt.errorbar(x,y,yerr,fmt='.')\n",
    "plt.plot(np.linspace(0,0.09,10), np.linspace(0,0.09,10),'k--')\n",
    "print(np.sum([np.array(x)<np.array(y)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_dist_hr = {}\n",
    "intra_dist_hr = {}\n",
    "\n",
    "self_hr = {}\n",
    "for sub in subs:\n",
    "    self_hr[sub] = list(map(lambda x: persim.heat(dgms[sub][x], dgms[sub][x]), [0,1]))\n",
    "\n",
    "for s, ss in combinations(subs,2):\n",
    "    if s not in intra_dist_hr:\n",
    "        intra_dist_hr[s] = 2.0* persim.heat(dgms[s][0],dgms[s][1])/(self_hr[s][0] + self_hr[s][1]);\n",
    "        inter_dist_hr[s] = []\n",
    "    if ss not in intra_dist_hr:\n",
    "        intra_dist_hr[ss] = 2.0*persim.heat(dgms[ss][0],dgms[ss][1])/(self_hr[ss][0] + self_hr[ss][1]);\n",
    "        inter_dist_hr[ss] = [];\n",
    "    d = 2.0*persim.heat(dgms[s][0],dgms[ss][1])/(self_hr[s][0] + self_hr[ss][1]);\n",
    "    inter_dist_hr[s].append(d);\n",
    "    d = 2.0 * persim.heat(dgms[s][1],dgms[ss][0])/(self_hr[s][1] + self_hr[ss][0]);\n",
    "    inter_dist_hr[ss].append(d);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x =  list(map(lambda x: intra_dist_hr[x], subs))\n",
    "y = list(map(lambda x: np.mean(inter_dist_hr[x]),subs))\n",
    "yerr = list(map(lambda x: np.std(inter_dist_hr[x]), subs))\n",
    "\n",
    "plt.plot(x,y,'o')\n",
    "plt.errorbar(x,y,yerr,fmt='.')\n",
    "plt.plot(np.linspace(0,0.09,10), np.linspace(0,0.09,10),'k--')\n",
    "print(np.sum([np.array(x)<np.array(y)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim = PersImage(pixels=([30,30]), spread=None)\n",
    "imgs = pim.transform(diagrams_h1)\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for i in range(100):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    pim.show(imgs[i])\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "imgs_array = np.array([img.flatten() for img in imgs])\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array, labels, test_size=0.40, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "print(lr.score(X_test, y_test))\n",
    "\n",
    "inverse_image = np.copy(lr.coef_).reshape((30,30))\n",
    "plt.figure()\n",
    "pim.show(inverse_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
