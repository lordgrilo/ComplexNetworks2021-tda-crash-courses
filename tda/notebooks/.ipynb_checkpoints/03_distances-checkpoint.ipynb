{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import persim\n",
    "import persim.plot\n",
    "import ripser\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = datasets.make_circles()[0]\n",
    "data_noisy = datasets.make_circles(noise=0.1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(data_clean[:,0], data_clean[:,1], label=\"clean data\")\n",
    "plt.scatter(data_noisy[:,0], data_noisy[:,1], label=\"noisy data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate $H_1$ diagrams for each of the data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm_clean = ripser.ripser(data_clean)['dgms'][1]\n",
    "dgm_noisy = ripser.ripser(data_noisy)['dgms'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripser.plot_dgms([dgm_clean, dgm_noisy] , labels=['Clean $H_1$', 'Noisy $H_1$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute and visualize Bottleneck distance\n",
    "\n",
    "**bottleneck distance**: Bottleneck distance measures the similarity between two persistence diagrams. It's the shortest distance _b_ for which there exists a perfect matching between the points of the two diagrams (+ all the diagonal points) such that any couple of matched points are at distance at most _b_.   \n",
    "\n",
    "The `bottleneck` function has the option of returning the matching when the parameter `matching` is set to `True`. With the returned data, we can use the `plot.bottleneck_matching` function to visualize which persistence points contributed to the distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bottleneck, (matching, D) = persim.bottleneck(dgm_clean, dgm_noisy, matching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.plot.bottleneck_matching(dgm_clean, dgm_noisy, matching, D, labels=['Clean $H_1$', 'Noisy $H_1$'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default option of `matching=False` will return just the distance if that is all you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.bottleneck(dgm_clean, dgm_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgm1 = np.array([\n",
    "    [0.5, 1],\n",
    "    [0.6, 1.1]\n",
    "])\n",
    "dgm2 = np.array([\n",
    "    [0.5, 1.1],\n",
    "#     [0.7,0.8]\n",
    "])\n",
    "\n",
    "d, (matching, D) = persim.bottleneck(\n",
    "    dgm1,\n",
    "    dgm2,\n",
    "    matching=True\n",
    ")\n",
    "\n",
    "persim.plot.bottleneck_matching(dgm1, dgm2, matching, D, labels=['Clean $H_1$', 'Noisy $H_1$'])\n",
    "plt.title(f\"Distance {d:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matching, D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliced Wasserstein distance\n",
    "\n",
    "\n",
    "Sliced Wasserstein Kernels for persistence diagrams were introduced by [Carriere et al, 2017](https://arxiv.org/abs/1706.03358) and implemented by Alice Patania.\n",
    "\n",
    "The general idea is to compute an approximation of the Wasserstein distance by computing the distance in 1-dimension repeatedly, and use the results as measure. To do so, the points of each persistence diagram are projected onto M lines that pass through (0,0) and forms an angle theta with the axis x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.sliced_wasserstein(dgm_clean, dgm_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `M` controls the number of iterations to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ms = range(5, 100, 2)\n",
    "ds = [persim.sliced_wasserstein(dgm_clean, dgm_noisy, M=M) for M in Ms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Ms, ds)\n",
    "plt.xlabel(\"M Iterations\")\n",
    "plt.ylabel(\"Approximate Distance\")\n",
    "plt.title(\"Relationship between M and distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heat Kernel Distance\n",
    "\n",
    "We also implement the heat kernel distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.heat(dgm_clean, dgm_noisy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter `sigma` controls the heat diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmas = np.linspace(0.1, 10, 100)\n",
    "ds = [persim.heat(dgm_clean, dgm_noisy, sigma=s) for s in sigmas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sigmas, ds)\n",
    "plt.xlabel(\"Heat diffusion parameter\")\n",
    "plt.ylabel(\"Approximate Distance\")\n",
    "plt.title(\"Relationship between sigma and distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the heat kernel is quite slow in general, but also one of the most discriminative (out of experience). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise\n",
    "- measure the distance between tori of various dimensions, sampling density etc...\n",
    "- generate a few different persistent diagrams (anyway you want) and compare how well the distances work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hint for first exercise: import stuff from the previous notebooks (duh..)\n",
    "# help for the second exercise: use data in '../data/ToyData_PD_TextFiles/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# solution to the second exercise:\n",
    "import os\n",
    "pd_data = {}\n",
    "data_dir = '../data/ToyData_PD_TextFiles/'\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    pd_data[f] = np.genfromtxt(data_dir + f);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "from itertools import combinations\n",
    "now = time.time();\n",
    "h = np.zeros((10,10));\n",
    "keys = np.array([*pd_data])[list(np.random.randint(0,high=600,size=10))];\n",
    "\n",
    "for i,j in combinations(range(len(keys)),2):\n",
    "    h[i,j] = persim.heat(pd_data[keys[i]], pd_data[keys[j]])\n",
    "print(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(h+h.T)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "- Can you cluster "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
