{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persistence Images in Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how you can use persistent homology and persistence images to classify datasets.  We construct datasets from two classes, one just noise and the other noise with a big circle in the middle. We then compute persistence diagrams with [Ripser.py](https://github.com/scikit-tda/ripser.py) and convert them to persistence images with [PersIm](https://github.com/scikit-tda/persim). Using these persistence images, we build a Logistic Regression model using a LASSO penatly to classify whether the dataset has a circle or not.  We find, using only default values, classification has a mean accuracy greater than 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ripser import Rips\n",
    "from persim import PersImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct data\n",
    "\n",
    "Generate N datasets that are just noise and N that are noise with a circle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "N_per_class = int(N / 2)\n",
    "N_in_class = 400\n",
    "\n",
    "def noise(N, scale):\n",
    "    return scale * np.random.random((N, 2))\n",
    "\n",
    "def circle(N, scale, offset):\n",
    "    return offset + scale * datasets.make_circles(n_samples=N, factor=0.4, noise=0.05)[0]\n",
    "    \n",
    "just_noise = [noise(N_in_class, 150) for _ in range(N_per_class)]\n",
    "\n",
    "half = int(N_in_class / 2)\n",
    "with_circle = [np.concatenate((circle(half, 50, 70), noise(half, 150)))\n",
    "               for _ in range(N_per_class)]\n",
    "\n",
    "datas = []\n",
    "datas.extend(just_noise)\n",
    "datas.extend(with_circle)\n",
    "\n",
    "# Define labels\n",
    "labels = np.zeros(N)\n",
    "labels[N_per_class:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10,5)\n",
    "\n",
    "xs, ys = just_noise[0][:,0], just_noise[0][:,1]\n",
    "axs[0].scatter(xs, ys)\n",
    "axs[0].set_title(\"Example noise dataset\")\n",
    "axs[0].set_aspect('equal', 'box')\n",
    "\n",
    "xs_, ys_ = with_circle[0][:,0], with_circle[0][:,1]\n",
    "axs[1].scatter(xs_, ys_)\n",
    "axs[1].set_title(\"Example noise with circle dataset\")\n",
    "axs[1].set_aspect('equal', 'box')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute homology of each dataset\n",
    "\n",
    "Generate the persistence diagram of $H_1$ for each of the datasets generated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rips = Rips(maxdim=1, coeff=2)\n",
    "diagrams = [rips.fit_transform(data) for data in datas]\n",
    "diagrams_h1 = [rips.fit_transform(data)[1] for data in datas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(121)\n",
    "\n",
    "rips.plot(diagrams_h1[0], show=False)\n",
    "plt.title(\"PD of $H_1$ for just noise\")\n",
    "\n",
    "plt.subplot(122)\n",
    "rips.plot(diagrams_h1[-1], show=False)\n",
    "plt.title(\"PD of $H_1$ for circle w/ noise\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute persistence images\n",
    "\n",
    "Convert each persistence diagram into a persistence image. Flatten each image into a vector format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pim = PersImage(pixels=[20,20], spread=1)\n",
    "imgs = pim.transform(diagrams_h1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = np.array([img.flatten() for img in imgs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7.5))\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(240+i+1)\n",
    "    pim.show(imgs[i], ax)\n",
    "    plt.title(\"PI of $H_1$ for noise\")\n",
    "\n",
    "for i in range(4):\n",
    "    ax = plt.subplot(240+i+5)\n",
    "    pim.show(imgs[-(i+1)], ax)\n",
    "    plt.title(\"PI of $H_1$ for circle w/ noise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify the datasets from the persistence images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array, labels, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So these are perfectly descriminative? Seems almost too good to be true. Let's see what features are important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse analysis on LASSO \n",
    "\n",
    "Visualizing the regression coefficients as a persistence image shows us which features of the images are most important for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverse_image = np.copy(lr.coef_).reshape((20,20))\n",
    "pim.show(inverse_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slightly less trivial: classify shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pd_data = {}\n",
    "data_dir = '../data/ToyData_PD_TextFiles/'\n",
    "\n",
    "for f in os.listdir(data_dir):\n",
    "    pd_data[f] = np.genfromtxt(data_dir + f);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 1\n",
    "dgms = []\n",
    "labels = []\n",
    "for f in pd_data:\n",
    "    args = f.split('_');\n",
    "    if args[-1][0] == str(dim):\n",
    "        dgms.append(pd_data[f])\n",
    "        labels.append(args[2]);\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = pim.transform(dgms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_array = np.array([img.flatten() for img in imgs])\n",
    "X_train, X_test, y_train, y_test = train_test_split(imgs_array, labels, test_size=0.40, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.score(X_test, y_test), set(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
